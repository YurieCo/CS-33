{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf290
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww26360\viewh20380\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural

\f0\fs24 \cf0 \
//*\
#include "common_decl.h"\
#define image_1(i,j) img1[i+j*w]\
#define image_2(i,j) img2[i+j*w]\
#define jh(a,b) j_h[a*256+b]\
\
\
//Optimize the code present in this file.\
\
\
int* joint_h(int* a,float* img1,float* img2,int w, int h)\
\{\
\
	int *j_h=a;\
\
	int i,j;\
	for (i=0;i<w;i++)    \
		for(j=0;j<h;j++)\
			jh(((int)image_1(i,j)),((int)image_2(i,j)))+=1;\
	return j_h;\
\
\}\
\
float MI(float* image_1, float * image_2,int w, int h)\
\{\
	\
	//  Computes the Mutual Information between the two images.\
	 	int* a=(int *)calloc(sizeof(int),256*256);\
	joint_h(a,image_1,image_2,w,h);\
	int i,j;\
	float *b=(float *) malloc(256*256*sizeof(float));\
	for(i=0;i<256*256;i++)\
		b[i]=a[i]/(float)(256*256);\
	float* y_marg=(float *) calloc(sizeof(float),256);  \
	float* x_marg=(float *) calloc(sizeof(float),256);  \
\
	for(i=0;i<256;i++)\
		for(j=0;j<256;j++)\
		\{\
			y_marg[i]+=b[i*256+j];\
			x_marg[j]+=b[i*256+j];\
		\}\
	float Hy=0;\
	float Hx=0;\
	float Hxy=0;\
	for (i=0;i<256;i++)  \
		if( y_marg[i]!=0)\
			Hy +=-y_marg[i]*log2(y_marg[i]);\
\
\
	for (i=0;i<256;i++)\
		if( x_marg[i]!=0 )\
			Hx += -x_marg[i]*log2(x_marg[i]);\
	for(i=0;i<256*256;i++)\
		if (b[i]!=0)\
			Hxy += -b[i]*log2(b[i]);\
     free(a);\
	 free(b);\
	 free(x_marg);\
	 free(y_marg);\
	return Hx+ Hy - Hxy;\
\}\
\
\
\
inline\
__device__ int getI()\
\{\
    return threadIdx.x + blockIdx.x*blockDim.x;//collumn\
\}\
\
inline\
__device__ int getJ()\
\{\
    return threadIdx.y + blockIdx.y*blockDim.y;//row\
\}\
\
__global__ void interpGPU(float* in, float* out, float* x_dis, float* y_dis, int w, int h)\
\{\
    int i = getI();//collumn\
    int j = getJ();//row\
    //out of bounds\
    if(i >= w || j >= h)\
    	return;\
    \
    int index = i + j*w;\
    float ii = i + x_dis[index];\
    float jj = j + y_dis[index];\
	\
	if(ii<0 || ii>w-1 || jj<0 || jj>h-1)\
		out[index]=nan("outofbound");\
	else\
	\{\
    	if(ii<0)\
    		ii=0;\
		else if(ii>w-1)\
    		ii=w-1;\
		if(jj<0)\
    		jj=0;\
		else if(jj>h-1)\
    		jj=h-1;\
		\
		int ii_int=(int)trunc(ii);\
		int jj_int=(int)trunc(jj);\
		if(ii_int==w-1)\
    		ii_int--;\
		if(jj_int==h-1)\
    		jj_int--;\
		\
		out[index]=(1+ii_int-ii)*(1+jj_int-jj)*in[ii_int+w*jj_int]\
			+(ii-ii_int)*(1+jj_int-jj)*in[(ii_int+1)+w*jj_int]\
			+(1+ii_int-ii)*(jj-jj_int)*in[ii_int+w*(jj_int+1)]\
			+(ii-ii_int)*(jj-jj_int)*in[(ii_int+1)+w*(jj_int+1)];\
	\}\
\}\
\
__global__ void computeGradientGPU(float* img2, float* grad_x_out, float* grad_y_out, int w, int h)\
\{\
	int i = getI();\
    int j = getJ();\
	if(i >= w || j >= h)\
    	return;\
    \
    int index = i + w*j;\
    \
    if(i == 0)\
    	grad_x_out[index] = img2[(i+1)+w*j]-img2[i+w*j];\
    else if(i == w-1)\
    	grad_x_out[index] = img2[i+w*j]-img2[(i-1)+w*j];\
    else\
    	grad_x_out[index] = (img2[(i+1)+w*j]-img2[(i-1)+w*j])/2;\
    \
    if(j == 0)\
    	grad_y_out[index] = img2[i+w*(j+1)]-img2[i+w*j];\
    else if(j == h-1)\
    	grad_y_out[index] = img2[i+w*j]-img2[i+w*(j-1)];\
    else\
    	grad_y_out[index] = (img2[i+w*(j+1)]-img2[i+w*(j-1)])/2;\
\}\
\
const int bw = 28;//effective block width\
const int bh = 12;//effective block height\
\
//blocking would help\
__global__ void doubleLoop1(\
	float* x_dis_tmp, float* y_dis_tmp,\
    float* x_dis, float* y_dis,\
    float* Tx1, float* Ty1,\
    float* T1, float* img1,\
    float a, float b, float dt,\
    int w, int h)\
\{\
    const int sw = bw+4;\
    const int sh = bh+4;\
    int i = threadIdx.x-2 + bw*blockIdx.x;\
    int j = threadIdx.y-2 + bh*blockIdx.y;\
    int si = threadIdx.x;\
    int sj = threadIdx.y;\
    __shared__ float s_x_dis[sw*sh];\
    __shared__ float s_y_dis[sw*sh];\
    \
    if(i >= 0 && i < w && j >= 0 && j < h)\
    \{//fill in the shared arrays\
    	s_x_dis[si + sw*sj] = x_dis[i + w*j];\
    	s_y_dis[si + sw*sj] = y_dis[i + w*j];\
    \}\
    __syncthreads();\
    \
	#define u1_temp(i,j) x_dis_tmp[(i)+w*(j)]\
	#define u2_temp(i,j) y_dis_tmp[(i)+w*(j)]\
	#define u1(i,j)  s_x_dis[(i)+sw*(j)]\
	#define u2(i,j)  s_y_dis[(i)+sw*(j)]\
    #define Tx1(i,j)  Tx1[(i)+w*(j)]\
	#define Ty1(i,j)  Ty1[(i)+w*(j)]\
	#define T1(i,j)  T1[(i)+w*(j)]\
	#define R(i,j)  img1[(i)+w*(j)]\
    if(si > 1 && si < sw-2 && sj > 1 && sj < sh-2)\
	\{\
    	if(!(i < 2 || i > w-3 || j < 2 || j > h-3))\
		\{\
	    	float commonFactor = T1(i,j)-R(i,j);\
	        \
			u1_temp(i,j)=a*(u1(si,sj)-dt*Tx1(i,j)*(commonFactor))-\
				b*(u1(si+2,sj)-6*u1(si+1,sj)-6*u1(si-1,sj)+u1(si-2,sj)+\
					u1(si,sj+2)-6*u1(si,sj+1)-6*u1(si,sj-1)+u1(si,sj-2)+\
					u1(si+1,sj+1)+u1(si-1,sj+1)+u1(si+1,sj-1)+u1(si-1,sj-1));\
	\
			u2_temp(i,j)=a*(u2(si,sj)-dt*Ty1(i,j)*(commonFactor))-\
				b*(u2(si+2,sj)-6*u2(si+1,sj)-6*u2(si-1,sj)+u2(si-2,sj)+\
					u2(si,sj+2)-6*u2(si,sj+1)-6*u2(si,sj-1)+u2(si,sj-2)+\
					u2(si+1,sj+1)+u2(si-1,sj+1)+u2(si+1,sj-1)+u2(si-1,sj-1));\
    	    \
		\}\
    \}\
    \
\}\
\
float compute_MI_iterate(float* img1,float* img2,int iter_max,int w,int h)\{\
\
	\
	//Comutes the MI for given images for 'iter_max' iterations. Do not change the number of iterations.\
	\
    //all device arrays\
	float* x_dis=0;//needs to be zeroed\
	float* y_dis=0;//needs to be zeroed\
	float* x_dis_tmp=0;\
	float* y_dis_tmp=0;\
	float* T1=0;//needs to be zeroed\
	float* Tx1=0;//needs to be zeroed\
	float* Ty1=0;//needs to be zeroed\
    \
    float* dimg1=0;//device image 1\
    float* dimg2=0;//device image 2\
    float* grad_x=0;//device gradient x\
    float* grad_y=0;//device gradient y\
    \
    int num_bytes = sizeof(float)*w*h;\
    int shared_bytes = sizeof(float)*(bw+4)*(bh+4)*2;\
    \
    cudaMalloc((void**)&x_dis, num_bytes);\
    cudaMalloc((void**)&y_dis, num_bytes);\
    cudaMalloc((void**)&x_dis_tmp, num_bytes);\
    cudaMalloc((void**)&y_dis_tmp, num_bytes);\
    cudaMalloc((void**)&T1, num_bytes);\
    cudaMalloc((void**)&Tx1, num_bytes);\
    cudaMalloc((void**)&Ty1, num_bytes);\
    \
    cudaMalloc((void**)&dimg1, num_bytes);\
    cudaMalloc((void**)&dimg2, num_bytes);\
    cudaMalloc((void**)&grad_x, num_bytes);\
    cudaMalloc((void**)&grad_y, num_bytes);\
    \
    if(!(x_dis || y_dis || x_dis_tmp || y_dis_tmp || T1 || Tx1 || Ty1 || dimg1 || dimg2 || grad_x || grad_y))\
    	return 0;\
    \
    //set up initial states of arrays\
    cudaMemcpy(dimg1, img1, num_bytes, cudaMemcpyHostToDevice);\
    cudaMemcpy(dimg2, img2, num_bytes, cudaMemcpyHostToDevice);\
    \
    cudaMemset(x_dis, 0, num_bytes);\
    cudaMemset(y_dis, 0, num_bytes);\
    cudaMemset(x_dis_tmp, 0, num_bytes);\
    cudaMemset(y_dis_tmp, 0, num_bytes);\
    cudaMemset(T1, 0, num_bytes);\
    cudaMemset(Tx1, 0, num_bytes);\
    cudaMemset(Ty1, 0, num_bytes);\
    \
    cudaThreadSynchronize();\
	\
    dim3 grid, block, block2;\
    \
    block.x = bw;\
    block.y = bh;\
    grid.x = ceil(w/(float)bw);\
    grid.y = ceil(h/(float)bh);\
    block2.x = bw+4;//same block size + 4 thread buffer\
    block2.y = bh+4;\
    \
    computeGradientGPU<<<grid, block>>>(dimg2, grad_x, grad_y, w, h);\
    cudaThreadSynchronize();\
    \
	for(int iter=0;iter<iter_max;iter++)\
	\{\
        interpGPU<<<grid, block>>>(dimg2, T1, x_dis, y_dis, w, h);\
        interpGPU<<<grid, block>>>(grad_x, Tx1, x_dis, y_dis, w, h);\
        interpGPU<<<grid, block>>>(grad_y, Ty1, x_dis, y_dis, w, h);\
		\
		cudaThreadSynchronize();\
        \
        doubleLoop1<<<grid, block2, shared_bytes>>>(\
			x_dis_tmp, y_dis_tmp,\
			x_dis, y_dis,\
			Tx1, Ty1,\
			T1, dimg1,\
			a, b, dt,\
			w, h);\
        \
        float* tmp = x_dis_tmp;\
        x_dis_tmp = x_dis;\
        x_dis = tmp;\
        \
        tmp = y_dis_tmp;\
        y_dis_tmp = y_dis;\
        y_dis = tmp;\
        \
        //sync here\
        cudaThreadSynchronize();\
	\}\
    \
	//write back from device\
    float* hT1 = (float*) malloc(sizeof(float)*w*h);//host T1\
    cudaMemcpy(hT1, T1, num_bytes, cudaMemcpyDeviceToHost);\
    cudaThreadSynchronize();\
    //delete stuff\
	cudaFree(x_dis);\
	cudaFree(y_dis);\
	cudaFree(x_dis_tmp);\
	cudaFree(y_dis_tmp);\
	cudaFree(T1);\
	cudaFree(Tx1);\
    cudaFree(Ty1);\
    \
    cudaFree(dimg1);\
    cudaFree(dimg2);\
    cudaFree(grad_x);\
    cudaFree(grad_y);\
    \
	float res1 =  MI(hT1,img1,w,h);\
	\
    free(hT1);\
    \
	return res1;\
\}\
}